# =============================================================================
# agents/host/orchestrator.py
# =============================================================================

"""
Gemini(OpenAI) LLMì„ ì‚¬ìš©í•´ ì‚¬ìš©ì ì˜ë„ë¥¼ íŒŒì•…í•˜ê³ 
ì ì ˆí•œ Child Agentë¡œ ìœ„ì„(delegate)í•˜ëŠ” OrchestratorAgent.
"""

# Python 3.7+ í˜¸í™˜ì„±ì„ ìœ„í•œ future annotations ì„í¬íŠ¸
from __future__ import annotations

# UUID ìƒì„±
import uuid
# íƒ€ì… íŒíŠ¸
from typing import Any, Dict, List

# JSON ì²˜ë¦¬
import json

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv

# â”€â”€â”€â”€â”€â”€â”€ Google ADK / LLM â”€â”€â”€â”€â”€â”€â”€

# Google ADKì˜ LLM ì—ì´ì „íŠ¸
from google.adk.agents.llm_agent import LlmAgent
# LiteLLM ëª¨ë¸ (ë‹¤ì–‘í•œ LLM ì§€ì›)
from google.adk.models.lite_llm import LiteLlm
# ì½ê¸° ì „ìš© ì»¨í…ìŠ¤íŠ¸
from google.adk.agents.readonly_context import ReadonlyContext
# ë„êµ¬ ì»¨í…ìŠ¤íŠ¸
from google.adk.tools.tool_context import ToolContext
# ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°
from google.adk.runners import Runner
# ì¸ë©”ëª¨ë¦¬ ì„¸ì…˜ ì„œë¹„ìŠ¤
from google.adk.sessions import InMemorySessionService
# ì¸ë©”ëª¨ë¦¬ ë©”ëª¨ë¦¬ ì„œë¹„ìŠ¤
from google.adk.memory.in_memory_memory_service import InMemoryMemoryService
# ì¸ë©”ëª¨ë¦¬ ì•„í‹°íŒ©íŠ¸ ì„œë¹„ìŠ¤
from google.adk.artifacts import InMemoryArtifactService

# â”€â”€â”€â”€â”€â”€â”€ A2A Connector â”€â”€â”€â”€â”€â”€â”€

# ì—ì´ì „íŠ¸ ì—°ê²° ëª¨ë“ˆ
from .agent_connect import AgentConnector
# ë©”ëª¨ë¦¬ ê´€ë¦¬ ëª¨ë“ˆ
from .memory import ConversationMemory

# â”€â”€â”€â”€â”€â”€â”€ ë©”ì‹œì§€ ë˜í•‘ìš© â”€â”€â”€â”€â”€â”€â”€
# Google GenAI íƒ€ì…
from google.genai import types

# â”€â”€â”€â”€â”€â”€â”€ íƒ€ì… ì •ì˜ â”€â”€â”€â”€â”€â”€â”€
# A2A íƒ€ì…ë“¤
from a2a.types import AgentCard, Task

# â”€â”€â”€â”€â”€â”€â”€ Custom Logging Configuration â”€â”€â”€â”€â”€â”€â”€
# ì»¤ìŠ¤í…€ ë¡œê±°
from utilities.custom_logger import get_logger

# í˜„ì¬ ëª¨ë“ˆ ë¡œê±° ìƒì„±
logger = get_logger(__name__)

# â”€â”€â”€â”€â”€â”€â”€ Get API Key From .env â”€â”€â”€â”€â”€â”€â”€

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# â”€â”€â”€â”€â”€â”€â”€ OrchestratorAgent Set-Up â”€â”€â”€â”€â”€â”€â”€

class OrchestratorAgent:
    """LLM + Toolë¡œ child-agent í˜¸ì¶œì„ ì¡°í•©"""

    # ì§€ì›í•˜ëŠ” ì½˜í…ì¸  íƒ€ì… ì •ì˜
    SUPPORTED_CONTENT_TYPES = ["text", "text/plain"]

    def __init__(self, agent_cards: list[AgentCard]):
        # Child-agent ì´ë¦„ â†” AgentConnector ë§¤í•‘
        self.connectors: dict[str, AgentConnector] = {
            card.name: AgentConnector(card.name, card.url) for card in agent_cards
        }

        # ğŸ”¥ í•µì‹¬: agent_cardsë¥¼ ì €ì¥í•´ì„œ ì¬í™œìš©
        self.agent_cards = agent_cards  # â† ì´ í•œ ì¤„ë§Œ ì¶”ê°€
        # ğŸš€ ìƒˆë¡œìš´ ë¶€ë¶„: ì´ˆê¸°í™” ì‹œì ì— instruction ë¯¸ë¦¬ ìƒì„±
        self._cached_agent_info = self._generate_agent_info()

        # ë©”ëª¨ë¦¬ ì¶”ê°€
        self.memory = ConversationMemory()
        
        # LLM ì—ì´ì „íŠ¸ êµ¬ì„±
        self._agent = self._build_agent()
        
        # ê¸°ë³¸ ì‚¬ìš©ì ID
        self._user_id = "orchestrator_user"
        
        # ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° êµ¬ì„±
        self._runner = Runner(
            app_name=self._agent.name,
            agent=self._agent,
            artifact_service=InMemoryArtifactService(),
            session_service=InMemorySessionService(),
            memory_service=InMemoryMemoryService(),
        )

    def _generate_agent_info(self) -> str:
        """ì´ˆê¸°í™” ì‹œì ì— ì—ì´ì „íŠ¸ ì •ë³´ë¥¼ í•œ ë²ˆë§Œ ìƒì„±"""
        
        def format_agent_card(card: AgentCard) -> str:
            """AgentCardë¥¼ A2A ê·œê²©ì— ë§ì¶° í¬ë§·íŒ…"""
            
            # ê¸°ë³¸ ì •ë³´
            info_lines = [
                f"**{card.name}** (v{card.version})",
                f"  ğŸ“ Description: {card.description}",
                f"  ğŸŒ URL: {card.url}",
                f"  ğŸ“‹ Protocol: {getattr(card, 'protocolVersion', 'N/A')}"
            ]
            
            # í”„ë¡œë°”ì´ë” ì •ë³´
            if card.provider:
                provider_name = getattr(card.provider, 'name', 'Unknown')
                info_lines.append(f"  ğŸ¢ Provider: {provider_name}")
            
            # ì…ì¶œë ¥ ëª¨ë“œ
            if card.defaultInputModes:
                info_lines.append(f"  ğŸ“¥ Input Modes: {', '.join(card.defaultInputModes)}")
            if card.defaultOutputModes:
                info_lines.append(f"  ğŸ“¤ Output Modes: {', '.join(card.defaultOutputModes)}")
            
            # ëŠ¥ë ¥ ì •ë³´
            if card.capabilities:
                capabilities_info = []
                if hasattr(card.capabilities, 'streaming'):
                    capabilities_info.append(f"Streaming: {card.capabilities.streaming}")
                if capabilities_info:
                    info_lines.append(f"  âš¡ Capabilities: {', '.join(capabilities_info)}")
            
            # ìŠ¤í‚¬ ì •ë³´
            if card.skills:
                skills_info = []
                for skill in card.skills:
                    skill_parts = []
                    if hasattr(skill, 'name'):
                        skill_parts.append(f"Name: {skill.name}")
                    if hasattr(skill, 'description'):
                        skill_parts.append(f"Description: {skill.description}")
                    if hasattr(skill, 'examples') and skill.examples:
                        skill_parts.append(f"Examples: {', '.join(skill.examples)}")
                    if hasattr(skill, 'tags') and skill.tags:
                        skill_parts.append(f"Tags: {', '.join(skill.tags)}")
                    
                    if skill_parts:
                        skills_info.append(f"[{'; '.join(skill_parts)}]")
                
                if skills_info:
                    info_lines.append(f"  ğŸ› ï¸ Skills: {'; '.join(skills_info)}")
            
            # ì¶”ê°€ ì •ë³´ë“¤
            if hasattr(card, 'documentationUrl') and card.documentationUrl:
                info_lines.append(f"  ğŸ“š Documentation: {card.documentationUrl}")
            
            if hasattr(card, 'iconUrl') and card.iconUrl:
                info_lines.append(f"  ğŸ¨ Icon: {card.iconUrl}")
            
            if hasattr(card, 'preferredTransport') and card.preferredTransport:
                info_lines.append(f"  ğŸš€ Preferred Transport: {card.preferredTransport}")
            
            if hasattr(card, 'additionalInterfaces') and card.additionalInterfaces:
                interface_info = []
                for interface in card.additionalInterfaces:
                    if hasattr(interface, 'transport'):
                        interface_info.append(interface.transport)
                if interface_info:
                    info_lines.append(f"  ğŸ”— Additional Interfaces: {', '.join(interface_info)}")
            
            if hasattr(card, 'security') and card.security:
                info_lines.append(f"  ğŸ”’ Security: Required")
            
            if hasattr(card, 'supportsAuthenticatedExtendedCard') and card.supportsAuthenticatedExtendedCard:
                info_lines.append(f"  ğŸ” Extended Card Support: Yes")
            
            return "\n".join(info_lines)
        
        # ëª¨ë“  ì—ì´ì „íŠ¸ ì •ë³´ë¥¼ í•œ ë²ˆë§Œ ìƒì„±
        agent_info = "\n\n".join(format_agent_card(card) for card in self.agent_cards)
        logger.a2a(f"ğŸ” [AGENT INFO] Available agents:\n{agent_info}")
        return agent_info
    # --------------- LLM Agent êµ¬ì„± ---------------

    def _build_agent(self) -> LlmAgent:
        """LLM ì—ì´ì „íŠ¸ ë¹Œë“œ"""
        return LlmAgent(
            # OpenAI GPT-4o ëª¨ë¸ ì‚¬ìš©
            model=LiteLlm(model="openai/gpt-4o"),
            name="orchestrator_agent",
            description="Routes user queries to child agents with planning.",
            # ë£¨íŠ¸ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ ì„¤ì •
            instruction=self._root_instruction,
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤
            tools=[
                self._list_agents,
                self._delegate_task,
                self._get_conversation_history,
                self._create_plan
            ],
        )

    def _root_instruction(self, ctx: ReadonlyContext) -> str:
        """LLMì—ê²Œ ì œê³µí•  ë£¨íŠ¸ ì¸ìŠ¤íŠ¸ëŸ­ì…˜"""
        # LLM Instruction ë°˜í™˜
        return (
            "You are a STRICT TASK ROUTER. Your ONLY job is to route user queries to appropriate remote agents.\n\n"

            "ğŸš¨ ABSOLUTE RULES (NEVER VIOLATE):\n"
            "1. NEVER provide direct answers to user questions\n"
            "2. NEVER use your own knowledge to answer anything\n"
            "3. ALWAYS delegate information queries to remote agents (except system/memory requests)\n"
            "4. ALWAYS create a plan using create_plan() before delegation\n"
            "5. ONLY respond directly for:\n"
            "   - Agent list requests (use list_agents())\n"
            "   - Conversation history requests (use get_conversation_history())\n"
            "   - System errors or failures\n"
            "   - Clarification requests when user input is unclear\n\n"

            "ğŸ“ SPECIAL POLICY FOR CONVERSATION HISTORY AND CONTEXT:\n"
            "- Whenever the user refers to or requests previous conversations (e.g., 'previous conversation', 'last time', 'what I said before', 'ì§€ë‚œ ë²ˆ ì–˜ê¸°', 'ì „ì— í–ˆë˜ ì§ˆë¬¸', 'ê·¸ë•Œ ëŒ€ë‹µ ê¸°ì–µë‚˜?', 'based on what I asked earlier', etc.), you MUST first analyze the user's intent and request.\n"
            "- If the user is simply asking whether you remember, or wants a confirmation (e.g., 'Do you remember our conversation?', 'ë‚˜ë‘ ëŒ€í™”í–ˆë˜ ê±° ê¸°ì–µë‚˜?'), reply briefly that you remember and have the conversation history stored, without outputting the entire conversation, unless the user explicitly requests to see the history.\n"
            "- If the user requests to see all previous conversations, or explicitly asks for the history (e.g., 'show me the conversation', 'ëŒ€í™” ê¸°ë¡ ë‹¤ ë³´ì—¬ì¤˜', 'ì§€ë‚œ ëŒ€í™” ëª¨ë‘ ì•Œë ¤ì¤˜'), you MUST output the entire raw result of get_conversation_history(), verbatim, with no omission, summarization, or paraphrasing.\n"
            "- If the user requests a summary or asks a question based on a previous conversation (e.g., 'summarize what we discussed before', 'ì§€ë‚œë²ˆ ì–˜ê¸° ê¸°ë°˜ìœ¼ë¡œ ì•Œë ¤ì¤˜'), you MUST use get_conversation_history() as reference context for agent calls or your output, and make it clear which previous parts are relevant.\n"
            "- If the history is too long for one reply, display as much as possible and inform the user about truncation."

            
            "ğŸ“‹ MANDATORY WORKFLOW:\n"
            "Step 1: ANALYZE the user query intent and scope:\n"
            "   - Is it a simple confirmation request? â†’ Brief direct response\n"
            "   - Is it a specific information request? â†’ Plan and delegate\n"
            "   - Is it a detailed history request? â†’ Use appropriate tool with matching scope\n"
            "   - Is it a complex request combining multiple needs? â†’ Handle each component appropriately\n"
            "Step 2: PLAN using create_plan() - explain which agent to use, why, and the required step order.\n"
            "Step 3: For each step in the plan, generate the **minimal, agent-specific sub-query** for the target agent, based on its purpose and specialization. "
            "Do NOT simply forward or paraphrase the entire user query unless it is truly required for that agent to function. "
            "For example, when invoking a time agent, send only a direct time request (e.g., 'What is the current time?'). "
            "When invoking an agent that needs previous step results (such as a food agent needing time information), synthesize a new sub-query by combining ONLY the necessary outputs from prior agents with the specific user intent. "
            "Always respond to every tool_call_id with a proper tool message. If multiple tools are called, reply to each one in order."
            "NEVER include more context than needed, and always minimize the query. \n"
            "Step 4: DELEGATE using delegate_task() to send each sub-query and required context to the corresponding agent.\n"
            "Step 5: RELAY each agent's response without any modification or addition.\n\n"
            
            "ğŸ”— CONTEXT POLICY:\n"
            "- When delegating to a remote agent, always include **only the minimum required context for that specific agent and sub-query**.\n"
            "- If the user query requires a multi-turn chain (delegation to multiple agents), for each agent, always generate a specialized sub-query and pass ONLY the outputs from agents"
            "- Do NOT send the entire conversation or all agent results by default. Dynamically construct the context to include only the necessary outputs from previous steps, never more.\n"
            "- For real-time or time-sensitive queries (time, date, weather, stock prices, etc.), always fetch **fresh** data from the appropriate agent, even if previous similar results exist.\n"
            "- If the user query requires combining or synthesizing results from many agents, do so step-by-step: first gather the required data, then pass it to the next relevant agent as context for final synthesis.\n"
            "- Never include irrelevant information in agent calls. The more minimal the query and context, the better.\n"

            "ğŸ¯ AGENT SELECTION & SCALABILITY:\n"
            "- Select agents based on their specializations and the requirements of the query.\n"
            "- In cases where many agents might be relevant (large-scale scenarios), prioritize only those directly related to the query. Do NOT broadcast or fan out to all agents unless the task truly requires all their data.\n"
            "- If a query requires a large number of agent results (e.g., aggregate info from many agents), manage context size and agent call efficiency carefullyâ€”**plan, fetch, and compose results modularly.**\n"

            "âŒ FORBIDDEN BEHAVIORS:\n"
            "- Never answer questions yourself, never summarize or synthesize beyond routing.\n"
            "- Never simply copy and forward the original user query to all agents.\n"
            "- Do not include unnecessary context or history when delegating.\n"
            "- Never overload agents with irrelevant information or excessive context.\n"
            "- Never simply copy and forward the original user query to all agents. Always create step- and agent-specific sub-queries.\n"

            "âš ï¸ IMPORTANT NOTES:\n"
            "- You are a ROUTER, not a knowledge provider. Route efficiently, contextually, and with minimal overhead.\n"
            "- For each agent, pass only what is necessary for that agent to fulfill its role.\n"
            "- For complex workflows, dynamically manage dependencies and context.\n"
            "- Trust agents to provide accurate answersâ€”never alter or interpret their outputs yourself.\n"

            f"Available agents and informations:\n{self._cached_agent_info}\n\n"

            "Remember: ROUTE, DON'T ANSWER. For each step, generate and delegate only the minimal, most relevant sub-query and context for the agent, based strictly on the agent's function and the planned workflow."
        )


    # ----- Tool 1 -----

    def _list_agents(self) -> list[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡ ë°˜í™˜"""
        # ì—ì´ì „íŠ¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        agent_list = list(self.connectors.keys())
        
        # ë¡œê·¸ ì¶œë ¥
        logger.a2a(f"ğŸ” [TOOL_CALL] list_agents() â†’ {agent_list}")
        return agent_list

    # ----- Tool 2 -----

    async def _delegate_task(
        self,
        agent_name: str,
        message: str,
        tool_context: ToolContext,
        **kwargs        # â† ì´ê±° ì¶”ê°€!
    ) -> str:
        """
        íŠ¹ì • ì—ì´ì „íŠ¸ì—ê²Œ ì‘ì—… ìœ„ì„ (êµ¬ì¡°í™”ëœ context object ì „ë‹¬, granularity ì¡°ì ˆ)
        """

        # user_id, chat_id ì¶”ì¶œ
        user_id = tool_context.state.get("user_id", "")
        chat_id = tool_context.state.get("chat_id", "")

        # [step_number] í”Œëœë³„(ì¦‰, ì´ë²ˆ ìš”ì²­ë³„) ì¹´ìš´í„° ì¦ê°€
        if "step_number" not in tool_context.state:
            tool_context.state["step_number"] = 1
        else:
            tool_context.state["step_number"] += 1
        step_number = tool_context.state["step_number"]

        logger.a2a(f"\tğŸŸ¢ [EXECUTE-{step_number}] {agent_name} ì‹¤í–‰ ì¤‘...")

        # Agent validation
        if agent_name not in self.connectors:
            raise ValueError(f"Unknown agent: {agent_name}")

        # 3) context object ìƒì„± (ì—¬ê¸°ì„œ ì›í•˜ëŠ” í˜•íƒœë¡œ ì¡°ì •)
        context_obj = {
            "user_message": message,
        }

        logger.a2a(f"\tğŸŸ¢ [CONTEXT] {agent_name}ì—ê²Œ messeage : {message} ì „ë‹¬ ")

        try:
            # 4) json ì§ë ¬í™”í•´ì„œ ì „ë‹¬ (agentì—ì„œ objectë¡œ ë°”ë¡œ íŒŒì‹± ê°€ëŠ¥)
            result = await self.connectors[agent_name].send_task(
                json.dumps(context_obj), chat_id
            )

            # ì•„ë˜ ê²°ê³¼ íŒŒì‹±/ì €ì¥ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼
            if hasattr(result, 'history') and result.history:
                if result.history[-1].parts:
                    last_part = result.history[-1].parts[0]
                    if hasattr(last_part, 'text'):
                        response_text = last_part.text
                    elif hasattr(last_part, 'root') and hasattr(last_part.root, 'text'):
                        response_text = last_part.root.text
                    else:
                        response_text = "ì‘ë‹µì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            elif hasattr(result, 'parts') and result.parts:
                last_part = result.parts[0]
                if hasattr(last_part, 'text'):
                    response_text = last_part.text
                elif hasattr(last_part, 'root') and hasattr(last_part.root, 'text'):
                    response_text = last_part.root.text
                else:
                    response_text = "ì‘ë‹µì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            else:
                response_text = "ì‘ë‹µì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            # ê²°ê³¼ ì €ì¥ (step ì¶”ê°€ ê°€ëŠ¥)
            self.memory.add_agent_result(user_id, chat_id, agent_name, response_text, step=step_number)
            logger.a2a(f"\tâœ… [EXECUTE-{step_number}] {agent_name} Success.")
            return response_text

        except Exception as e:
            logger.error(f"ì—ì´ì „íŠ¸ {agent_name} í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            logger.error(f"âŒ [EXECUTE-{step_number}] {agent_name} Fail: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. {agent_name} ì—ì´ì „íŠ¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    # ----- Tool 3 -----

    def _get_conversation_history(self, tool_context: ToolContext) -> str:
        """ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°"""
        # ì»¨í…ìŠ¤íŠ¸ì—ì„œ ID ì¶”ì¶œ
        user_id = tool_context.state.get("user_id", "")
        chat_id = tool_context.state.get("chat_id", "")
        
        # ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” ê¸°ë¡ ë°˜í™˜
        return self.memory.get_conversation_history(user_id, chat_id)

    # ----- Tool 4 -----

    def _create_plan(
        self,
        query: str,
        reasoning: str,
        tool_context: ToolContext,
    ) -> str:
        """ì‹¤í–‰ ê³„íš ìƒì„±"""
        
        # Plan ìƒì„± ë¡œê·¸
        logger.a2a(
            f"\tğŸ“‹ [PLAN] Execution plan created:\n"
            f"\tâ”œâ”€â”€ User Query: {query}\n"
            f"\tâ”œâ”€â”€ Reasoning: {reasoning}\n"
            f"\tâ””â”€â”€ Next Action: Delegate to appropriate agent"
        )

        # ê³„íš ì„¤ì • ì™„ë£Œ ë©”ì‹œì§€ ë°˜í™˜
        return "A Plan is set up"

    # ---- ì§„ì…ì  (Executorì—ì„œ ì‚¬ìš©) ----

    async def invoke(self, query: str, user_id: str, chat_id: str) -> str:
        """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í˜¸ì¶œ ì§„ì…ì """
        
        # ì‚¬ìš©ì ì…ë ¥ì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        self.memory.add_conversation(user_id, chat_id, "user", query)
        
        # ì›Œí¬í”Œë¡œìš° ì‹œì‘ ë¡œê·¸
        logger.a2a(f"\tğŸŸ¢ [START WORKFLOW] Start workflow for User ID={user_id}")
        logger.a2a(f"\tğŸŸ¢ [USER_INPUT] {query} (Chat ID={chat_id})")

        # ì„¸ì…˜ ì„œë¹„ìŠ¤ì— chat_idë¥¼ session_idë¡œ ì „ë‹¬
        session = await self._runner.session_service.get_session(
            app_name=self._agent.name,
            user_id=self._user_id,
            session_id=chat_id,
        )

        if session is None:
            # ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            session = await self._runner.session_service.create_session(
                app_name=self._agent.name,
                user_id=self._user_id,
                session_id=chat_id,
                state={"user_id": user_id, "chat_id": chat_id},
            )
        else:
            # ê¸°ì¡´ ì„¸ì…˜ì— ìƒíƒœ ì—…ë°ì´íŠ¸
            session.state["user_id"] = user_id
            session.state["chat_id"] = chat_id

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì½˜í…ì¸  ìƒì„±
        content = types.Content(
            role="user",
            parts=[types.Part.from_text(text=query)],
        )

        # ì´ë²¤íŠ¸ ìˆ˜ì§‘ìš© ë¦¬ìŠ¤íŠ¸
        events = []
        
        # ì—ì´ì „íŠ¸ ì‹¤í–‰ (ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼)
        async for ev in self._runner.run_async(
            user_id=self._user_id,
            session_id=session.id,
            new_message=content,
        ):
            events.append(ev)

        # ì‘ë‹µì´ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        if not events or not events[-1].content or not events[-1].content.parts:
            return ""

        # ìµœì¢… ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        final_response = "\n".join(
            p.text for p in events[-1].content.parts if getattr(p, "text", "")
        )

        # ì‘ë‹µ ë¡œê·¸
        logger.a2a(f"\tâœ… [AGENT] {final_response}")
        logger.a2a(f"\tâœ… [END WORKFLOW] End workflow for Chat ID={chat_id}")

        # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        self.memory.add_conversation(user_id, chat_id, "assistant", final_response)

        # ìµœì¢… ì‘ë‹µ ë°˜í™˜
        return final_response
